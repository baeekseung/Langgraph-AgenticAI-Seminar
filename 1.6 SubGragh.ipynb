{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ad6c60",
   "metadata": {},
   "source": [
    "# 1.6 SubGraph: LangGraph Agent를 Node로 활용하는 방법\n",
    "\n",
    "- [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://arxiv.org/abs/2403.14403)논문을 구현합니다\n",
    "- LangGraph 공식문서의 흐름을 따라갑니다\n",
    "    - 공식문서의 흐름은 간소화된 버전입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa64f8",
   "metadata": {},
   "source": [
    "![adaptive-rag](https://i.imgur.com/tbICSxY.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3974637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: list\n",
    "    answer: str\n",
    "    \n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb60ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "tavily_search_tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    include_images=True,\n",
    ")\n",
    "\n",
    "def web_search(state: AgentState) -> AgentState:\n",
    "    query = state['query']\n",
    "    results = tavily_search_tool.invoke(query)\n",
    "\n",
    "    return {'context': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LangChain 허브에서 프롬프트를 가져옵니다\n",
    "generate_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# OpenAI의 GPT-4o 모델을 사용합니다\n",
    "generate_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "def web_generate(state: AgentState) -> AgentState:\n",
    "    # state에서 문맥과 질문을 추출합니다\n",
    "    context = state['context']\n",
    "    query = state['query']\n",
    "    \n",
    "    # 프롬프트와 모델, 출력 파서를 연결하여 체인을 생성합니다\n",
    "    rag_chain = generate_prompt | generate_llm | StrOutputParser()\n",
    "    \n",
    "    # 체인을 사용하여 답변을 생성합니다\n",
    "    response = rag_chain.invoke({'question': query, 'context': context})\n",
    "    \n",
    "    # 생성된 답변을 'answer'로 반환합니다\n",
    "    return {'answer': response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc4216",
   "metadata": {},
   "source": [
    "- 간단한 질문에 답변을 하는 경우 작은 모델을 활용해서 비용을 저감하고, 답변 생성 속도를 향상시킬 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# OpenAI의 GPT-4o-mini 모델을 사용합니다\n",
    "basic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "def basic_generate(state: AgentState) -> AgentState:\n",
    "    # state에서 질문을 추출합니다\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    # 기본 LLM 체인을 생성합니다\n",
    "    basic_llm_chain = basic_llm | StrOutputParser()\n",
    "\n",
    "    # 체인을 사용하여 답변을 생성합니다\n",
    "    llm_response = basic_llm_chain.invoke(query)\n",
    "\n",
    "    # 생성된 답변을 'answer'로 반환합니다\n",
    "    return {\"answer\": llm_response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd07d4",
   "metadata": {},
   "source": [
    "- 사용자의 질문이 들어오면 `router` 노드에서 사용자의 질문을 분석해서 적절한 노드로 이동합니다\n",
    "    - 사용자의 질문에 관한 내용이 vector store에 있는 경우 `retrieve_agent` 노드로 이동합니다\n",
    "    - 사용자의 질문이 간단한 경우 `basic_generate` 노드로 이동합니다\n",
    "    - 사용자의 질문이 웹 검색을 통해 답변을 얻을 수 있는 경우 `web_search` 노드로 이동합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec255c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class Route(BaseModel):\n",
    "    target: Literal[\"vector_store\", \"llm\", \"web_search\"] = Field(\n",
    "        description=\"The target for the query to answer\"\n",
    "    )\n",
    "\n",
    "router_system_prompt = \"\"\"\n",
    "You are an expert at routing a user's question to 'vector_store', 'llm', or 'web_search'.\n",
    "'vector_store' contains information about income tax up to December 2024.\n",
    "if you think the question is simple enough use 'llm'\n",
    "if you think you need to search the web to answer the question use 'web_search'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", router_system_prompt), (\"user\", \"{query}\")]\n",
    ")\n",
    "\n",
    "router_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "structured_router_llm = router_llm.with_structured_output(Route)\n",
    "\n",
    "\n",
    "def router(state: AgentState) -> Literal[\"vector_store\", \"llm\", \"web_search\"]:\n",
    "    # state에서 질문을 추출합니다\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    # 프롬프트와 구조화된 라우터 LLM을 연결하여 체인을 생성합니다\n",
    "    router_chain = router_prompt | structured_router_llm\n",
    "\n",
    "    # 체인을 사용하여 경로를 결정합니다\n",
    "    route = router_chain.invoke({\"query\": query})\n",
    "\n",
    "    # 결정된 경로의 타겟을 반환합니다\n",
    "    return route.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be1a906",
   "metadata": {},
   "source": [
    "- `node`를 추가하고 `edge`로 연결합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5170cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youth_month_rent_subgraph import graph as youth_month_rent_subgraph\n",
    "\n",
    "graph_builder.add_node(\"youth_month_rent_agent\", youth_month_rent_subgraph)\n",
    "graph_builder.add_node(\"web_search\", web_search)\n",
    "graph_builder.add_node(\"web_generate\", web_generate)\n",
    "graph_builder.add_node(\"basic_generate\", basic_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    START,\n",
    "    router,\n",
    "    {\n",
    "        \"vector_store\": \"youth_month_rent_agent\",\n",
    "        \"llm\": \"basic_generate\",\n",
    "        \"web_search\": \"web_search\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"web_search\", \"web_generate\")\n",
    "graph_builder.add_edge(\"web_generate\", END)\n",
    "graph_builder.add_edge(\"basic_generate\", END)\n",
    "graph_builder.add_edge(\"youth_month_rent_agent\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8811cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\"query\": \"대한민국의 수도는 어디인가요?\"}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {'query': '나 차 있는데 괜찮아?'}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ba0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\"query\": \"역삼 맛집을 추천해주세요\"}\n",
    "graph.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgentTuto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
